{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/pt/test1/ELM/data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/pt/test1/ELM/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/pt/test1/ELM/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/pt/test1/ELM/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "#from utils.data_utils import img_to_array, array_to_img\n",
    "from transformer import spatial_transformer_network as stn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/home/pt/test1/ELM/data\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-787cbf7838df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'input_img' is not defined"
     ]
    }
   ],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "batch=128\n",
    "out_H = 28\n",
    "out_W = 28\n",
    "out_dims = (out_H, out_W)\n",
    "B, H, W, C = batch,28,28,1\n",
    "#angleDeg = 10\n",
    "#angleRad = angleDeg * np.pi / 180\n",
    "#theta = np.array([[np.cos(angleRad), -np.sin(angleRad), 0], [np.sin(angleRad), np.cos(angleRad), 0]])\n",
    "\n",
    "theta = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "theta2 = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "#theta2 = np.array([[0., 1, 0], [1, 0., 0]])\n",
    "x = tf.placeholder(tf.float32, [None, H, W, C])\n",
    "\n",
    "# create localisation network and convolutional layer\n",
    "with tf.variable_scope('spatial_transformer_0'):\n",
    "\n",
    "    # create a fully-connected layer with 6 output nodes\n",
    "    n_fc = 6\n",
    "    W_fc1 = tf.Variable(tf.zeros([H*W*C, n_fc]), name='W_fc1')\n",
    "\n",
    "    # affine transformation\n",
    "    theta = theta.astype('float32')\n",
    "    theta = theta.flatten()\n",
    "\n",
    "    b_fc1 = tf.Variable(initial_value=theta, name='b_fc1')\n",
    "    h_fc1 = tf.matmul(tf.zeros([B, H*W*C]), W_fc1) + b_fc1\n",
    "    h_trans = stn(x, h_fc1, out_dims)\n",
    "    \n",
    "with tf.variable_scope('spatial_transformer_02'):\n",
    "\n",
    "    # create a fully-connected layer with 6 output nodes\n",
    "    n_fc2 = 6\n",
    "    W_fc12 = tf.Variable(tf.zeros([H*W*C, n_fc]), name='W_fc12')\n",
    "\n",
    "    # affine transformation\n",
    "    theta2 = theta2.astype('float32')\n",
    "    theta2 = theta2.flatten()\n",
    "\n",
    "    b_fc12 = tf.Variable(initial_value=theta2, name='b_fc12')\n",
    "    h_fc12 = tf.matmul(tf.zeros([B, H*W*C]), W_fc12) + b_fc12\n",
    "    h_trans2 = stn(h_trans, h_fc12, out_dims)\n",
    "    \n",
    "# run session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "batch_x, _ = mnist.train.next_batch(batch)\n",
    "input_img = np.reshape(batch_x, [-1,28, 28, 1])\n",
    "y = sess.run(h_trans2, feed_dict={x: input_img})\n",
    "print(y.shape)\n",
    "y = np.reshape(y, (128,784))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABaCAYAAACc0dMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ1NmZmZmGfwf717TT9LVRt4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABaCAYAAACc0dMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfMghAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n=10\n",
    "canvas_orig1 = np.empty((28 * 1, 28 * n))\n",
    "\n",
    "for i in range(1):\n",
    "    # MNIST test set8\n",
    "    g = (batch_x  + 1.) / 2.\n",
    "    # Reverse colours for better display\n",
    "    g = -1 * (g - 1)\n",
    "    #g=np.dot(batch_x, np.transpose(net.beta)) \n",
    "    #g=np.dot(net2input,net.beta)\n",
    "    # Display original images\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas_orig1[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] =g [j].reshape([28, 28])\n",
    "        \n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_orig1, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "n=10\n",
    "canvas_orig = np.empty((28 * 1, 28 * n))\n",
    "\n",
    "for i in range(1):\n",
    "    # MNIST test set8\n",
    "    g = (y  + 1.) / 2.\n",
    "    # Reverse colours for better display\n",
    "    g = -1 * (g - 1)\n",
    "    #g=np.dot(batch_x, np.transpose(net.beta)) \n",
    "    #g=np.dot(net2input,net.beta)\n",
    "    # Display original images\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] =g [j].reshape([28, 28])\n",
    "        \n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss: 647.381958\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-066f852cfdc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step %i, Loss: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 30000\n",
    "batch_size = 64\n",
    "\n",
    "# Network Parameters\n",
    "image_dim = 784 # MNIST images are 28x28 pixels\n",
    "hidden_dim = 512\n",
    "latent_dim = 20\n",
    "\n",
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n",
    "\n",
    "# Variables\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(glorot_init([image_dim, hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'decoder_h1': tf.Variable(glorot_init([latent_dim, hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([hidden_dim, image_dim]))\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([latent_dim])),\n",
    "    'decoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([image_dim]))\n",
    "}\n",
    "\n",
    "# Building the encoder\n",
    "\n",
    "out_H = 28\n",
    "out_W = 28\n",
    "out_dims = (out_H, out_W)\n",
    "B, H, W, C = batch_size,28,28,1\n",
    "angleDeg = 45\n",
    "angleRad = angleDeg * np.pi / 180\n",
    "theta = np.array([[np.cos(angleRad), -np.sin(angleRad), 0], [np.sin(angleRad), np.cos(angleRad), 0]])\n",
    "\n",
    "#theta = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, H, W, C])\n",
    "\n",
    "# create localisation network and convolutional layer\n",
    "with tf.variable_scope('spatial_transformer_0'):\n",
    "\n",
    "    # create a fully-connected layer with 6 output nodes\n",
    "    n_fc = 6\n",
    "    W_fc1 = tf.Variable(tf.zeros([H*W*C, n_fc]), name='W_fc1')\n",
    "\n",
    "    # affine transformation\n",
    "    theta = theta.astype('float32')\n",
    "    theta = theta.flatten()\n",
    "\n",
    "    b_fc1 = tf.Variable(initial_value=theta, name='b_fc1')\n",
    "    h_fc1 = tf.matmul(tf.zeros([B, H*W*C]), W_fc1) + b_fc1\n",
    "    h_trans = stn(x, h_fc1, out_dims)\n",
    "    \n",
    "input_image=tf.reshape(h_trans, (batch_size,784))    \n",
    "encoder = tf.matmul(input_image, weights['encoder_h1']) + biases['encoder_b1']\n",
    "encoder = tf.nn.tanh(encoder)\n",
    "z_mean = tf.matmul(encoder, weights['z_mean']) + biases['z_mean']\n",
    "z_std = tf.matmul(encoder, weights['z_std']) + biases['z_std']\n",
    "\n",
    "# Sampler: Normal (gaussian) random distribution\n",
    "eps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n",
    "                       name='epsilon')\n",
    "z = z_mean + tf.exp(z_std / 2) * eps\n",
    "\n",
    "# Building the decoder (with scope to re-use these layers later)\n",
    "decoder = tf.matmul(z, weights['decoder_h1']) + biases['decoder_b1']\n",
    "decoder = tf.nn.tanh(decoder)\n",
    "decoder = tf.matmul(decoder, weights['decoder_out']) + biases['decoder_out']\n",
    "decoder = tf.nn.sigmoid(decoder)\n",
    "\n",
    "# Define VAE Loss\n",
    "def vae_loss(x_reconstructed, x_true):\n",
    "    # Reconstruction loss\n",
    "    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n",
    "                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n",
    "    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n",
    "    # KL Divergence loss\n",
    "    kl_div_loss = 1 + z_std - tf.square(z_mean) - tf.exp(z_std)\n",
    "    kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n",
    "    return tf.reduce_mean(encode_decode_loss + kl_div_loss)\n",
    "\n",
    "loss_op = vae_loss(decoder, input_image)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start Training\n",
    "# Start a new TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "   \n",
    "    input_img = np.reshape(batch_x, [-1,28, 28, 1])\n",
    "    # Train\n",
    "    feed_dict = {x: input_img}\n",
    "    _, l = sess.run([train_op, loss_op], feed_dict=feed_dict)\n",
    "    if i % 1000 == 0 or i == 1:\n",
    "        print('Step %i, Loss: %f' % (i, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss: 843.635559\n",
      "Step 1000, Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2a57424a81c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step %i, Loss: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 30000\n",
    "batch_size = 64\n",
    "\n",
    "# Network Parameters\n",
    "image_dim = 784 # MNIST images are 28x28 pixels\n",
    "hidden_dim = 512\n",
    "latent_dim = 20\n",
    "\n",
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))\n",
    "\n",
    "# Variables\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(glorot_init([image_dim, hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'decoder_h1': tf.Variable(glorot_init([latent_dim, hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([hidden_dim, image_dim]))\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([latent_dim])),\n",
    "    'decoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([image_dim]))\n",
    "}\n",
    "\n",
    "# Building the encoder\n",
    "\n",
    "out_H = 28\n",
    "out_W = 28\n",
    "out_dims = (out_H, out_W)\n",
    "B, H, W, C = batch_size,28,28,1\n",
    "\n",
    "theta = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, H, W, C])\n",
    "\n",
    "# create localisation network and convolutional layer\n",
    "with tf.variable_scope('spatial_transformer_0'):\n",
    "\n",
    "    # create a fully-connected layer with 6 output nodes\n",
    "    n_fc = 6\n",
    "    W_fc1 = tf.Variable(tf.zeros([H*W*C, n_fc]), name='W_fc1')\n",
    "\n",
    "    # affine transformation\n",
    "    theta = theta.astype('float32')\n",
    "    theta = theta.flatten()\n",
    "\n",
    "    b_fc1 = tf.Variable(initial_value=theta, name='b_fc1')\n",
    "    h_fc1 = tf.matmul(tf.zeros([B, H*W*C]), W_fc1) + b_fc1\n",
    "    h_trans = stn(x, h_fc1, out_dims)\n",
    "    \n",
    "input_image=tf.reshape(h_trans, (batch_size,784))    \n",
    "encoder = tf.matmul(input_image, weights['encoder_h1']) + biases['encoder_b1']\n",
    "encoder = tf.nn.tanh(encoder)\n",
    "z_mean = tf.matmul(encoder, weights['z_mean']) + biases['z_mean']\n",
    "z_std = tf.matmul(encoder, weights['z_std']) + biases['z_std']\n",
    "\n",
    "# Sampler: Normal (gaussian) random distribution\n",
    "eps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n",
    "                       name='epsilon')\n",
    "z = z_mean + tf.exp(z_std / 2) * eps\n",
    "\n",
    "# Building the decoder (with scope to re-use these layers later)\n",
    "decoder = tf.matmul(z, weights['decoder_h1']) + biases['decoder_b1']\n",
    "decoder = tf.nn.tanh(decoder)\n",
    "decoder = tf.matmul(decoder, weights['decoder_out']) + biases['decoder_out']\n",
    "decoder = tf.nn.sigmoid(decoder)\n",
    "\n",
    "decoder = tf.reshape(h_trans, (batch_size,H, W, C)) \n",
    "\n",
    "with tf.variable_scope('spatial_transformer_02'):\n",
    "\n",
    "    # create a fully-connected layer with 6 output nodes\n",
    "    n_fc2 = 6\n",
    "    W_fc12 = tf.Variable(tf.zeros([H*W*C, n_fc]), name='W_fc12')\n",
    "\n",
    "    # affine transformation\n",
    "    theta = theta.astype('float32')\n",
    "    theta = theta.flatten()\n",
    "\n",
    "    b_fc12 = tf.Variable(initial_value=theta, name='b_fc12')\n",
    "    h_fc12 = tf.matmul(tf.zeros([B, H*W*C]), W_fc12) + b_fc12\n",
    "    decoder = stn(decoder, h_fc12, out_dims)\n",
    "    \n",
    "decoder = tf.reshape(decoder, (batch_size,784))    \n",
    "# Define VAE Loss\n",
    "def vae_loss(x_reconstructed, x_true):\n",
    "    # Reconstruction loss\n",
    "    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n",
    "                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n",
    "    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n",
    "    # KL Divergence loss\n",
    "    kl_div_loss = 1 + z_std - tf.square(z_mean) - tf.exp(z_std)\n",
    "    kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n",
    "    return tf.reduce_mean(encode_decode_loss + kl_div_loss)\n",
    "\n",
    "loss_op = vae_loss(decoder, input_image)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start Training\n",
    "# Start a new TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "   \n",
    "    input_img = np.reshape(batch_x, [-1,28, 28, 1])\n",
    "    # Train\n",
    "    feed_dict = {x: input_img}\n",
    "    _, l = sess.run([train_op, loss_op], feed_dict=feed_dict)\n",
    "    if i % 1000 == 0 or i == 1:\n",
    "        print('Step %i, Loss: %f' % (i, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 2) for Tensor 'Placeholder_24:0', which has shape '(?, 20)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-751c07e342ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mz_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnoise_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_mu\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcanvas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mx_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (64, 2) for Tensor 'Placeholder_24:0', which has shape '(?, 20)'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing\n",
    "# Generate images from noise, using the generator network.\n",
    "def sample_z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "n = 6\n",
    "noise_dim=20\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "for i in range(n):\n",
    "    # Noise input.\n",
    "    z_mu = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
    "    # Generate image from noise.\n",
    "    #decoder = np.dot(z, net4.beta) \n",
    "    #decoder= np.dot(decoder, net3.beta) \n",
    "    #decoder= np.dot(decoder, net2.beta) \n",
    "    g = sess.run(decoder, feed_dict={noise_input: z_mu})\n",
    "    #g= np.dot(z, net.beta) \n",
    "    # Rescale values to the original [0, 1] (from tanh -> [-1, 1])\n",
    "    g = (g + 1.) / 2.\n",
    "    # Reverse colours for better display\n",
    "    g = -1 * (g - 1)\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
